{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0903 01:02:08.739199 12492 deprecation_wrapper.py:119] From C:\\Users\\chauh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has apparently already been downloaded and unpacked.\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/batches.meta\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_1\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_2\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_3\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_4\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_5\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/test_batch\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Dropout,Flatten,BatchNormalization\n",
    "model=Sequential()\n",
    "from keras.layers import MaxPooling2D\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import cifar10\n",
    "from sklearn import datasets\n",
    "#from sklearn.decomposition import PCA\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cifar10.data_path = \"data/CIFAR-10/\"\n",
    "cifar10.maybe_download_and_extract()\n",
    "\n",
    "class_names = cifar10.load_class_names()\n",
    "class_names\n",
    "x_train_data, cls_train, labels_train = cifar10.load_training_data()\n",
    "x_test_data, cls_test, labels_test = cifar10.load_test_data()\n",
    "\n",
    "\n",
    "\n",
    "#print(labels_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0903 01:02:11.346980 12492 deprecation_wrapper.py:119] From C:\\Users\\chauh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0903 01:02:11.349972 12492 deprecation_wrapper.py:119] From C:\\Users\\chauh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0903 01:02:11.373908 12492 deprecation_wrapper.py:119] From C:\\Users\\chauh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0903 01:02:11.374937 12492 deprecation_wrapper.py:119] From C:\\Users\\chauh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0903 01:02:11.401867 12492 deprecation_wrapper.py:119] From C:\\Users\\chauh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0903 01:02:11.497577 12492 deprecation_wrapper.py:119] From C:\\Users\\chauh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0903 01:02:11.502563 12492 deprecation.py:506] From C:\\Users\\chauh\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model.add(Conv2D(32,3,strides=(1,1),activation='relu',padding='same',input_shape=(32,32,3)))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same', data_format=None))\n",
    "model.add(Conv2D(32,3,strides=(1,1), activation=('relu'), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same', data_format=None))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64,3,strides=(1,1), activation=('relu') ,padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same', data_format=None))    \n",
    "model.add(Conv2D(64,3,strides=(1,1), activation=('relu') ,padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same', data_format=None)) \n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128,3,strides=(1,1), activation=('relu') ,padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same', data_format=None))\n",
    "model.add(Conv2D(128,3,strides=(1,1), activation=('relu') ,padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same', data_format=None))   \n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten()) \n",
    "          \n",
    "model.add(Dense(units=10,activation='relu'))\n",
    "#model.add(Dropout(0.8))\n",
    "model.add(Dense(units=10,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0903 01:02:11.778825 12492 deprecation_wrapper.py:119] From C:\\Users\\chauh\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initiate RMSprop optimizer\n",
    "#opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0903 01:02:11.931630 12492 deprecation.py:323] From C:\\Users\\chauh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "50000/50000 [==============================] - 333s 7ms/step - loss: 1.7889 - acc: 0.3371 - val_loss: 1.4454 - val_acc: 0.4739\n",
      "Epoch 2/200\n",
      "50000/50000 [==============================] - 332s 7ms/step - loss: 1.1272 - acc: 0.5884 - val_loss: 1.0109 - val_acc: 0.6489\n",
      "Epoch 3/200\n",
      "50000/50000 [==============================] - 329s 7ms/step - loss: 0.8777 - acc: 0.6887 - val_loss: 0.8798 - val_acc: 0.6873\n",
      "Epoch 4/200\n",
      "50000/50000 [==============================] - 328s 7ms/step - loss: 0.7605 - acc: 0.7343 - val_loss: 0.7872 - val_acc: 0.7264\n",
      "Epoch 5/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.6796 - acc: 0.7636 - val_loss: 0.6784 - val_acc: 0.7685\n",
      "Epoch 6/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.6167 - acc: 0.7855 - val_loss: 0.6345 - val_acc: 0.7840\n",
      "Epoch 7/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.5655 - acc: 0.8044 - val_loss: 0.5615 - val_acc: 0.8076\n",
      "Epoch 8/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.5330 - acc: 0.8159 - val_loss: 0.5557 - val_acc: 0.8119\n",
      "Epoch 9/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.4991 - acc: 0.8261 - val_loss: 0.6014 - val_acc: 0.7968\n",
      "Epoch 10/200\n",
      "50000/50000 [==============================] - 326s 7ms/step - loss: 0.4668 - acc: 0.8367 - val_loss: 0.5284 - val_acc: 0.8237\n",
      "Epoch 11/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.4481 - acc: 0.8459 - val_loss: 0.5303 - val_acc: 0.8218\n",
      "Epoch 12/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.4256 - acc: 0.8532 - val_loss: 0.5487 - val_acc: 0.8212\n",
      "Epoch 13/200\n",
      "50000/50000 [==============================] - 328s 7ms/step - loss: 0.4071 - acc: 0.8595 - val_loss: 0.5215 - val_acc: 0.8326\n",
      "Epoch 14/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.3870 - acc: 0.8655 - val_loss: 0.5298 - val_acc: 0.8237\n",
      "Epoch 15/200\n",
      "50000/50000 [==============================] - 328s 7ms/step - loss: 0.3756 - acc: 0.8681 - val_loss: 0.5033 - val_acc: 0.8365\n",
      "Epoch 16/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.3594 - acc: 0.8727 - val_loss: 0.4967 - val_acc: 0.8410\n",
      "Epoch 17/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.3505 - acc: 0.8771 - val_loss: 0.5060 - val_acc: 0.8365\n",
      "Epoch 18/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.3369 - acc: 0.8815 - val_loss: 0.4870 - val_acc: 0.8425\n",
      "Epoch 19/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.3289 - acc: 0.8852 - val_loss: 0.5556 - val_acc: 0.8237\n",
      "Epoch 20/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.3206 - acc: 0.8873 - val_loss: 0.4997 - val_acc: 0.8424\n",
      "Epoch 21/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.3115 - acc: 0.8898 - val_loss: 0.5392 - val_acc: 0.8261\n",
      "Epoch 22/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.3020 - acc: 0.8951 - val_loss: 0.4839 - val_acc: 0.8457\n",
      "Epoch 23/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.2891 - acc: 0.8995 - val_loss: 0.4851 - val_acc: 0.8467\n",
      "Epoch 24/200\n",
      "50000/50000 [==============================] - 328s 7ms/step - loss: 0.2833 - acc: 0.9010 - val_loss: 0.4853 - val_acc: 0.8458\n",
      "Epoch 25/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.2747 - acc: 0.9025 - val_loss: 0.4653 - val_acc: 0.8562\n",
      "Epoch 26/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.2712 - acc: 0.9027 - val_loss: 0.4695 - val_acc: 0.8553\n",
      "Epoch 27/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.2672 - acc: 0.9065 - val_loss: 0.4807 - val_acc: 0.8512\n",
      "Epoch 28/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.2532 - acc: 0.9095 - val_loss: 0.4752 - val_acc: 0.8580\n",
      "Epoch 29/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.2539 - acc: 0.9115 - val_loss: 0.5048 - val_acc: 0.8444\n",
      "Epoch 30/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.2478 - acc: 0.9113 - val_loss: 0.4655 - val_acc: 0.8571\n",
      "Epoch 31/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.2430 - acc: 0.9145 - val_loss: 0.4558 - val_acc: 0.8614\n",
      "Epoch 32/200\n",
      "50000/50000 [==============================] - 326s 7ms/step - loss: 0.2317 - acc: 0.9185 - val_loss: 0.5057 - val_acc: 0.8514\n",
      "Epoch 33/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.2299 - acc: 0.9182 - val_loss: 0.4959 - val_acc: 0.8504\n",
      "Epoch 34/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.2250 - acc: 0.9205 - val_loss: 0.4777 - val_acc: 0.8537\n",
      "Epoch 35/200\n",
      "50000/50000 [==============================] - 333s 7ms/step - loss: 0.2243 - acc: 0.9210 - val_loss: 0.4927 - val_acc: 0.8560\n",
      "Epoch 36/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.2194 - acc: 0.9228 - val_loss: 0.4951 - val_acc: 0.8557\n",
      "Epoch 37/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.2170 - acc: 0.9226 - val_loss: 0.5056 - val_acc: 0.8539\n",
      "Epoch 38/200\n",
      "50000/50000 [==============================] - 326s 7ms/step - loss: 0.2141 - acc: 0.9242 - val_loss: 0.5012 - val_acc: 0.8544\n",
      "Epoch 39/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.2095 - acc: 0.9256 - val_loss: 0.4862 - val_acc: 0.8625\n",
      "Epoch 40/200\n",
      "50000/50000 [==============================] - 326s 7ms/step - loss: 0.2085 - acc: 0.9258 - val_loss: 0.4932 - val_acc: 0.8572\n",
      "Epoch 41/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.2047 - acc: 0.9270 - val_loss: 0.5302 - val_acc: 0.8507\n",
      "Epoch 42/200\n",
      "50000/50000 [==============================] - 328s 7ms/step - loss: 0.2018 - acc: 0.9274 - val_loss: 0.4919 - val_acc: 0.8613\n",
      "Epoch 43/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.1967 - acc: 0.9301 - val_loss: 0.5226 - val_acc: 0.8566\n",
      "Epoch 44/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.1949 - acc: 0.9298 - val_loss: 0.4935 - val_acc: 0.8574\n",
      "Epoch 45/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.1925 - acc: 0.9322 - val_loss: 0.4841 - val_acc: 0.8636\n",
      "Epoch 46/200\n",
      "50000/50000 [==============================] - 328s 7ms/step - loss: 0.1931 - acc: 0.9312 - val_loss: 0.5132 - val_acc: 0.8558\n",
      "Epoch 47/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.1842 - acc: 0.9342 - val_loss: 0.4858 - val_acc: 0.8600\n",
      "Epoch 48/200\n",
      "50000/50000 [==============================] - 328s 7ms/step - loss: 0.1819 - acc: 0.9345 - val_loss: 0.4952 - val_acc: 0.8601\n",
      "Epoch 49/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.1838 - acc: 0.9347 - val_loss: 0.4991 - val_acc: 0.8626\n",
      "Epoch 50/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.1794 - acc: 0.9370 - val_loss: 0.5021 - val_acc: 0.8590\n",
      "Epoch 51/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.1784 - acc: 0.9366 - val_loss: 0.4807 - val_acc: 0.8674\n",
      "Epoch 52/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.1721 - acc: 0.9395 - val_loss: 0.5320 - val_acc: 0.8550\n",
      "Epoch 53/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.1750 - acc: 0.9362 - val_loss: 0.4828 - val_acc: 0.8651\n",
      "Epoch 54/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.1641 - acc: 0.9423 - val_loss: 0.5132 - val_acc: 0.8571\n",
      "Epoch 55/200\n",
      "50000/50000 [==============================] - 328s 7ms/step - loss: 0.1692 - acc: 0.9403 - val_loss: 0.5288 - val_acc: 0.8584\n",
      "Epoch 56/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.1673 - acc: 0.9407 - val_loss: 0.5053 - val_acc: 0.8617\n",
      "Epoch 57/200\n",
      "50000/50000 [==============================] - 328s 7ms/step - loss: 0.1652 - acc: 0.9412 - val_loss: 0.5181 - val_acc: 0.8587\n",
      "Epoch 58/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.1624 - acc: 0.9427 - val_loss: 0.4937 - val_acc: 0.8624\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.1632 - acc: 0.9431 - val_loss: 0.5344 - val_acc: 0.8568\n",
      "Epoch 60/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.1639 - acc: 0.9417 - val_loss: 0.5204 - val_acc: 0.8580\n",
      "Epoch 61/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.1573 - acc: 0.9437 - val_loss: 0.4974 - val_acc: 0.8677\n",
      "Epoch 62/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.1564 - acc: 0.9446 - val_loss: 0.5135 - val_acc: 0.8646\n",
      "Epoch 63/200\n",
      "50000/50000 [==============================] - 326s 7ms/step - loss: 0.1591 - acc: 0.9439 - val_loss: 0.5139 - val_acc: 0.8639\n",
      "Epoch 64/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.1491 - acc: 0.9473 - val_loss: 0.5124 - val_acc: 0.8630\n",
      "Epoch 65/200\n",
      "50000/50000 [==============================] - 328s 7ms/step - loss: 0.1524 - acc: 0.9468 - val_loss: 0.4938 - val_acc: 0.8672\n",
      "Epoch 66/200\n",
      "50000/50000 [==============================] - 334s 7ms/step - loss: 0.1480 - acc: 0.9473 - val_loss: 0.5133 - val_acc: 0.8635\n",
      "Epoch 67/200\n",
      "50000/50000 [==============================] - 329s 7ms/step - loss: 0.1478 - acc: 0.9469 - val_loss: 0.5072 - val_acc: 0.8623\n",
      "Epoch 68/200\n",
      "50000/50000 [==============================] - 330s 7ms/step - loss: 0.1461 - acc: 0.9480 - val_loss: 0.5013 - val_acc: 0.8689\n",
      "Epoch 69/200\n",
      "50000/50000 [==============================] - 327s 7ms/step - loss: 0.1435 - acc: 0.9494 - val_loss: 0.5061 - val_acc: 0.8621\n",
      "Epoch 70/200\n",
      "50000/50000 [==============================] - 339s 7ms/step - loss: 0.1456 - acc: 0.9465 - val_loss: 0.5158 - val_acc: 0.8621\n",
      "Epoch 71/200\n",
      "50000/50000 [==============================] - 385s 8ms/step - loss: 0.1441 - acc: 0.9486 - val_loss: 0.5100 - val_acc: 0.8656\n",
      "Epoch 72/200\n",
      "50000/50000 [==============================] - 364s 7ms/step - loss: 0.1406 - acc: 0.9493 - val_loss: 0.5115 - val_acc: 0.8667\n",
      "Epoch 73/200\n",
      "50000/50000 [==============================] - 358s 7ms/step - loss: 0.1363 - acc: 0.9509 - val_loss: 0.5148 - val_acc: 0.8683\n",
      "Epoch 74/200\n",
      "50000/50000 [==============================] - 354s 7ms/step - loss: 0.1418 - acc: 0.9498 - val_loss: 0.5396 - val_acc: 0.8614\n",
      "Epoch 75/200\n",
      "50000/50000 [==============================] - 372s 7ms/step - loss: 0.1392 - acc: 0.9500 - val_loss: 0.5207 - val_acc: 0.8675\n",
      "Epoch 76/200\n",
      "50000/50000 [==============================] - 386s 8ms/step - loss: 0.1359 - acc: 0.9522 - val_loss: 0.5123 - val_acc: 0.8680\n",
      "Epoch 77/200\n",
      "50000/50000 [==============================] - 369s 7ms/step - loss: 0.1355 - acc: 0.9515 - val_loss: 0.5295 - val_acc: 0.8630\n",
      "Epoch 78/200\n",
      "50000/50000 [==============================] - 346s 7ms/step - loss: 0.1342 - acc: 0.9534 - val_loss: 0.5334 - val_acc: 0.8664\n",
      "Epoch 79/200\n",
      "50000/50000 [==============================] - 330s 7ms/step - loss: 0.1363 - acc: 0.9518 - val_loss: 0.5058 - val_acc: 0.8644\n",
      "Epoch 80/200\n",
      "50000/50000 [==============================] - 334s 7ms/step - loss: 0.1359 - acc: 0.9519 - val_loss: 0.5313 - val_acc: 0.8613\n",
      "Epoch 81/200\n",
      "50000/50000 [==============================] - 341s 7ms/step - loss: 0.1347 - acc: 0.9526 - val_loss: 0.5271 - val_acc: 0.8667\n",
      "Epoch 82/200\n",
      "50000/50000 [==============================] - 357s 7ms/step - loss: 0.1320 - acc: 0.9535 - val_loss: 0.5460 - val_acc: 0.8630\n",
      "Epoch 83/200\n",
      "50000/50000 [==============================] - 382s 8ms/step - loss: 0.1321 - acc: 0.9534 - val_loss: 0.5170 - val_acc: 0.8668\n",
      "Epoch 84/200\n",
      "50000/50000 [==============================] - 389s 8ms/step - loss: 0.1274 - acc: 0.9543 - val_loss: 0.5091 - val_acc: 0.8684\n",
      "Epoch 85/200\n",
      "50000/50000 [==============================] - 387s 8ms/step - loss: 0.1245 - acc: 0.9556 - val_loss: 0.5120 - val_acc: 0.8692\n",
      "Epoch 86/200\n",
      "50000/50000 [==============================] - 362s 7ms/step - loss: 0.1274 - acc: 0.9544 - val_loss: 0.5233 - val_acc: 0.8697\n",
      "Epoch 87/200\n",
      "50000/50000 [==============================] - 337s 7ms/step - loss: 0.1295 - acc: 0.9539 - val_loss: 0.5169 - val_acc: 0.8677\n",
      "Epoch 88/200\n",
      "50000/50000 [==============================] - 331s 7ms/step - loss: 0.1216 - acc: 0.9575 - val_loss: 0.5262 - val_acc: 0.8670\n",
      "Epoch 89/200\n",
      "50000/50000 [==============================] - 348s 7ms/step - loss: 0.1286 - acc: 0.9543 - val_loss: 0.5165 - val_acc: 0.8684\n",
      "Epoch 90/200\n",
      "50000/50000 [==============================] - 362s 7ms/step - loss: 0.1226 - acc: 0.9559 - val_loss: 0.5155 - val_acc: 0.8683\n",
      "Epoch 91/200\n",
      "50000/50000 [==============================] - 349s 7ms/step - loss: 0.1255 - acc: 0.9556 - val_loss: 0.4992 - val_acc: 0.8686\n",
      "Epoch 92/200\n",
      "50000/50000 [==============================] - 366s 7ms/step - loss: 0.1202 - acc: 0.9571 - val_loss: 0.5452 - val_acc: 0.8654\n",
      "Epoch 93/200\n",
      "50000/50000 [==============================] - 376s 8ms/step - loss: 0.1205 - acc: 0.9573 - val_loss: 0.5275 - val_acc: 0.8654\n",
      "Epoch 94/200\n",
      "50000/50000 [==============================] - 371s 7ms/step - loss: 0.1210 - acc: 0.9564 - val_loss: 0.5443 - val_acc: 0.8659\n",
      "Epoch 95/200\n",
      "50000/50000 [==============================] - 357s 7ms/step - loss: 0.1241 - acc: 0.9552 - val_loss: 0.5292 - val_acc: 0.8648\n",
      "Epoch 96/200\n",
      "50000/50000 [==============================] - 361s 7ms/step - loss: 0.1202 - acc: 0.9570 - val_loss: 0.5549 - val_acc: 0.8599\n",
      "Epoch 97/200\n",
      "50000/50000 [==============================] - 359s 7ms/step - loss: 0.1230 - acc: 0.9554 - val_loss: 0.5202 - val_acc: 0.8632\n",
      "Epoch 98/200\n",
      "50000/50000 [==============================] - 386s 8ms/step - loss: 0.1148 - acc: 0.9581 - val_loss: 0.5203 - val_acc: 0.8715\n",
      "Epoch 99/200\n",
      "50000/50000 [==============================] - 386s 8ms/step - loss: 0.1185 - acc: 0.9584 - val_loss: 0.5194 - val_acc: 0.8689\n",
      "Epoch 100/200\n",
      "50000/50000 [==============================] - 339s 7ms/step - loss: 0.1182 - acc: 0.9576 - val_loss: 0.5518 - val_acc: 0.8654\n",
      "Epoch 101/200\n",
      "50000/50000 [==============================] - 331s 7ms/step - loss: 0.1119 - acc: 0.9605 - val_loss: 0.5345 - val_acc: 0.8671\n",
      "Epoch 102/200\n",
      "50000/50000 [==============================] - 352s 7ms/step - loss: 0.1198 - acc: 0.9578 - val_loss: 0.5313 - val_acc: 0.8606\n",
      "Epoch 103/200\n",
      "50000/50000 [==============================] - 353s 7ms/step - loss: 0.1115 - acc: 0.9608 - val_loss: 0.5223 - val_acc: 0.8699\n",
      "Epoch 104/200\n",
      "50000/50000 [==============================] - 353s 7ms/step - loss: 0.1154 - acc: 0.9587 - val_loss: 0.5178 - val_acc: 0.8688\n",
      "Epoch 105/200\n",
      "50000/50000 [==============================] - 353s 7ms/step - loss: 0.1134 - acc: 0.9598 - val_loss: 0.5173 - val_acc: 0.8707\n",
      "Epoch 106/200\n",
      "50000/50000 [==============================] - 345s 7ms/step - loss: 0.1124 - acc: 0.9595 - val_loss: 0.5484 - val_acc: 0.8609\n",
      "Epoch 107/200\n",
      "50000/50000 [==============================] - 352s 7ms/step - loss: 0.1116 - acc: 0.9607 - val_loss: 0.5400 - val_acc: 0.8701\n",
      "Epoch 108/200\n",
      "50000/50000 [==============================] - 366s 7ms/step - loss: 0.1108 - acc: 0.9615 - val_loss: 0.5686 - val_acc: 0.8567\n",
      "Epoch 109/200\n",
      "50000/50000 [==============================] - 350s 7ms/step - loss: 0.1096 - acc: 0.9613 - val_loss: 0.5320 - val_acc: 0.8717\n",
      "Epoch 110/200\n",
      "50000/50000 [==============================] - 351s 7ms/step - loss: 0.1116 - acc: 0.9614 - val_loss: 0.5171 - val_acc: 0.8703\n",
      "Epoch 111/200\n",
      "50000/50000 [==============================] - 353s 7ms/step - loss: 0.1117 - acc: 0.9600 - val_loss: 0.5276 - val_acc: 0.8706\n",
      "Epoch 112/200\n",
      "50000/50000 [==============================] - 351s 7ms/step - loss: 0.1073 - acc: 0.9619 - val_loss: 0.5716 - val_acc: 0.8579\n",
      "Epoch 113/200\n",
      "50000/50000 [==============================] - 362s 7ms/step - loss: 0.1109 - acc: 0.9610 - val_loss: 0.5432 - val_acc: 0.8632\n",
      "Epoch 114/200\n",
      "50000/50000 [==============================] - 374s 7ms/step - loss: 0.1058 - acc: 0.9621 - val_loss: 0.5476 - val_acc: 0.8688\n",
      "Epoch 115/200\n",
      "50000/50000 [==============================] - 367s 7ms/step - loss: 0.1052 - acc: 0.9627 - val_loss: 0.5352 - val_acc: 0.8686\n",
      "Epoch 116/200\n",
      "50000/50000 [==============================] - 390s 8ms/step - loss: 0.1083 - acc: 0.9622 - val_loss: 0.5180 - val_acc: 0.8709\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 379s 8ms/step - loss: 0.1065 - acc: 0.9632 - val_loss: 0.5448 - val_acc: 0.8636\n",
      "Epoch 118/200\n",
      "50000/50000 [==============================] - 391s 8ms/step - loss: 0.1057 - acc: 0.9622 - val_loss: 0.5322 - val_acc: 0.8743\n",
      "Epoch 119/200\n",
      "50000/50000 [==============================] - 358s 7ms/step - loss: 0.1024 - acc: 0.9636 - val_loss: 0.5390 - val_acc: 0.8708\n",
      "Epoch 120/200\n",
      "50000/50000 [==============================] - 373s 7ms/step - loss: 0.1069 - acc: 0.9627 - val_loss: 0.5500 - val_acc: 0.8727\n",
      "Epoch 121/200\n",
      "50000/50000 [==============================] - 395s 8ms/step - loss: 0.1048 - acc: 0.9628 - val_loss: 0.5535 - val_acc: 0.8681\n",
      "Epoch 122/200\n",
      "50000/50000 [==============================] - 383s 8ms/step - loss: 0.1016 - acc: 0.9647 - val_loss: 0.5311 - val_acc: 0.8724\n",
      "Epoch 123/200\n",
      "50000/50000 [==============================] - 407s 8ms/step - loss: 0.0987 - acc: 0.9640 - val_loss: 0.5526 - val_acc: 0.8669\n",
      "Epoch 124/200\n",
      "50000/50000 [==============================] - 374s 7ms/step - loss: 0.1041 - acc: 0.9637 - val_loss: 0.5222 - val_acc: 0.8690\n",
      "Epoch 125/200\n",
      "50000/50000 [==============================] - 345s 7ms/step - loss: 0.1027 - acc: 0.9631 - val_loss: 0.5353 - val_acc: 0.8724\n",
      "Epoch 126/200\n",
      "50000/50000 [==============================] - 343s 7ms/step - loss: 0.0984 - acc: 0.9651 - val_loss: 0.5510 - val_acc: 0.8697\n",
      "Epoch 127/200\n",
      "50000/50000 [==============================] - 340s 7ms/step - loss: 0.1020 - acc: 0.9644 - val_loss: 0.5273 - val_acc: 0.8716\n",
      "Epoch 128/200\n",
      "50000/50000 [==============================] - 351s 7ms/step - loss: 0.1008 - acc: 0.9643 - val_loss: 0.5556 - val_acc: 0.8652\n",
      "Epoch 129/200\n",
      "50000/50000 [==============================] - 363s 7ms/step - loss: 0.1016 - acc: 0.9644 - val_loss: 0.5439 - val_acc: 0.8669\n",
      "Epoch 130/200\n",
      "50000/50000 [==============================] - 362s 7ms/step - loss: 0.1007 - acc: 0.9638 - val_loss: 0.5489 - val_acc: 0.8689\n",
      "Epoch 131/200\n",
      "50000/50000 [==============================] - 372s 7ms/step - loss: 0.0990 - acc: 0.9653 - val_loss: 0.5651 - val_acc: 0.8650\n",
      "Epoch 132/200\n",
      "50000/50000 [==============================] - 379s 8ms/step - loss: 0.0979 - acc: 0.9659 - val_loss: 0.5555 - val_acc: 0.8734\n",
      "Epoch 133/200\n",
      "50000/50000 [==============================] - 366s 7ms/step - loss: 0.1001 - acc: 0.9650 - val_loss: 0.5515 - val_acc: 0.8677\n",
      "Epoch 134/200\n",
      "50000/50000 [==============================] - 337s 7ms/step - loss: 0.0975 - acc: 0.9657 - val_loss: 0.5360 - val_acc: 0.8741\n",
      "Epoch 135/200\n",
      "50000/50000 [==============================] - 351s 7ms/step - loss: 0.0970 - acc: 0.9656 - val_loss: 0.5588 - val_acc: 0.8691\n",
      "Epoch 136/200\n",
      "50000/50000 [==============================] - 347s 7ms/step - loss: 0.0971 - acc: 0.9649 - val_loss: 0.5885 - val_acc: 0.8630\n",
      "Epoch 137/200\n",
      "50000/50000 [==============================] - 338s 7ms/step - loss: 0.0924 - acc: 0.9676 - val_loss: 0.5467 - val_acc: 0.8734\n",
      "Epoch 138/200\n",
      "50000/50000 [==============================] - 334s 7ms/step - loss: 0.0962 - acc: 0.9660 - val_loss: 0.5603 - val_acc: 0.8679\n",
      "Epoch 139/200\n",
      "50000/50000 [==============================] - 334s 7ms/step - loss: 0.0973 - acc: 0.9658 - val_loss: 0.6132 - val_acc: 0.8643\n",
      "Epoch 140/200\n",
      "50000/50000 [==============================] - 339s 7ms/step - loss: 0.0972 - acc: 0.9665 - val_loss: 0.5607 - val_acc: 0.8708\n",
      "Epoch 141/200\n",
      "50000/50000 [==============================] - 400s 8ms/step - loss: 0.0973 - acc: 0.9663 - val_loss: 0.5400 - val_acc: 0.8745\n",
      "Epoch 142/200\n",
      "50000/50000 [==============================] - 374s 7ms/step - loss: 0.0940 - acc: 0.9670 - val_loss: 0.5434 - val_acc: 0.8704\n",
      "Epoch 143/200\n",
      "50000/50000 [==============================] - 353s 7ms/step - loss: 0.0948 - acc: 0.9663 - val_loss: 0.5564 - val_acc: 0.8670\n",
      "Epoch 144/200\n",
      "50000/50000 [==============================] - 354s 7ms/step - loss: 0.0936 - acc: 0.9669 - val_loss: 0.5469 - val_acc: 0.8717\n",
      "Epoch 145/200\n",
      "50000/50000 [==============================] - 362s 7ms/step - loss: 0.0936 - acc: 0.9665 - val_loss: 0.5598 - val_acc: 0.8691\n",
      "Epoch 146/200\n",
      "50000/50000 [==============================] - 349s 7ms/step - loss: 0.0950 - acc: 0.9665 - val_loss: 0.5934 - val_acc: 0.8649\n",
      "Epoch 147/200\n",
      "50000/50000 [==============================] - 356s 7ms/step - loss: 0.0962 - acc: 0.9662 - val_loss: 0.5440 - val_acc: 0.8739\n",
      "Epoch 148/200\n",
      "50000/50000 [==============================] - 382s 8ms/step - loss: 0.0947 - acc: 0.9669 - val_loss: 0.5434 - val_acc: 0.8718\n",
      "Epoch 149/200\n",
      "50000/50000 [==============================] - 357s 7ms/step - loss: 0.0937 - acc: 0.9672 - val_loss: 0.5527 - val_acc: 0.8713\n",
      "Epoch 150/200\n",
      "50000/50000 [==============================] - 344s 7ms/step - loss: 0.0894 - acc: 0.9691 - val_loss: 0.5597 - val_acc: 0.8677\n",
      "Epoch 151/200\n",
      "50000/50000 [==============================] - 337s 7ms/step - loss: 0.0941 - acc: 0.9660 - val_loss: 0.5414 - val_acc: 0.8701\n",
      "Epoch 152/200\n",
      "50000/50000 [==============================] - 335s 7ms/step - loss: 0.0939 - acc: 0.9666 - val_loss: 0.5594 - val_acc: 0.8684\n",
      "Epoch 153/200\n",
      "50000/50000 [==============================] - 358s 7ms/step - loss: 0.0924 - acc: 0.9669 - val_loss: 0.5582 - val_acc: 0.8723\n",
      "Epoch 154/200\n",
      "50000/50000 [==============================] - 337s 7ms/step - loss: 0.0924 - acc: 0.9677 - val_loss: 0.5480 - val_acc: 0.8685\n",
      "Epoch 155/200\n",
      "50000/50000 [==============================] - 333s 7ms/step - loss: 0.0908 - acc: 0.9674 - val_loss: 0.5811 - val_acc: 0.8626\n",
      "Epoch 156/200\n",
      "50000/50000 [==============================] - 356s 7ms/step - loss: 0.0910 - acc: 0.9671 - val_loss: 0.5480 - val_acc: 0.8740\n",
      "Epoch 157/200\n",
      "50000/50000 [==============================] - 397s 8ms/step - loss: 0.0876 - acc: 0.9690 - val_loss: 0.5756 - val_acc: 0.8666\n",
      "Epoch 158/200\n",
      "50000/50000 [==============================] - 373s 7ms/step - loss: 0.0903 - acc: 0.9683 - val_loss: 0.5615 - val_acc: 0.8684\n",
      "Epoch 159/200\n",
      "50000/50000 [==============================] - 381s 8ms/step - loss: 0.0888 - acc: 0.9689 - val_loss: 0.5503 - val_acc: 0.8723\n",
      "Epoch 160/200\n",
      "50000/50000 [==============================] - 380s 8ms/step - loss: 0.0907 - acc: 0.9676 - val_loss: 0.5672 - val_acc: 0.8716\n",
      "Epoch 161/200\n",
      "50000/50000 [==============================] - 379s 8ms/step - loss: 0.0894 - acc: 0.9680 - val_loss: 0.5632 - val_acc: 0.8710\n",
      "Epoch 162/200\n",
      "50000/50000 [==============================] - 378s 8ms/step - loss: 0.0864 - acc: 0.9691 - val_loss: 0.5573 - val_acc: 0.8747\n",
      "Epoch 163/200\n",
      "50000/50000 [==============================] - 374s 7ms/step - loss: 0.0898 - acc: 0.9683 - val_loss: 0.5651 - val_acc: 0.8714\n",
      "Epoch 164/200\n",
      "50000/50000 [==============================] - 405s 8ms/step - loss: 0.0890 - acc: 0.9683 - val_loss: 0.5621 - val_acc: 0.8719\n",
      "Epoch 165/200\n",
      "50000/50000 [==============================] - 404s 8ms/step - loss: 0.0879 - acc: 0.9687 - val_loss: 0.5418 - val_acc: 0.8721\n",
      "Epoch 166/200\n",
      "50000/50000 [==============================] - 369s 7ms/step - loss: 0.0883 - acc: 0.9693 - val_loss: 0.5599 - val_acc: 0.8715\n",
      "Epoch 167/200\n",
      "50000/50000 [==============================] - 390s 8ms/step - loss: 0.0877 - acc: 0.9696 - val_loss: 0.5445 - val_acc: 0.8717\n",
      "Epoch 168/200\n",
      "50000/50000 [==============================] - 377s 8ms/step - loss: 0.0892 - acc: 0.9685 - val_loss: 0.5667 - val_acc: 0.8690\n",
      "Epoch 169/200\n",
      "50000/50000 [==============================] - 367s 7ms/step - loss: 0.0832 - acc: 0.9703 - val_loss: 0.5580 - val_acc: 0.8727\n",
      "Epoch 170/200\n",
      "50000/50000 [==============================] - 360s 7ms/step - loss: 0.0881 - acc: 0.9688 - val_loss: 0.5537 - val_acc: 0.8715\n",
      "Epoch 171/200\n",
      "50000/50000 [==============================] - 351s 7ms/step - loss: 0.0868 - acc: 0.9697 - val_loss: 0.5889 - val_acc: 0.8634\n",
      "Epoch 172/200\n",
      "50000/50000 [==============================] - 371s 7ms/step - loss: 0.0887 - acc: 0.9690 - val_loss: 0.5409 - val_acc: 0.8709\n",
      "Epoch 173/200\n",
      "50000/50000 [==============================] - 354s 7ms/step - loss: 0.0886 - acc: 0.9687 - val_loss: 0.5813 - val_acc: 0.8706\n",
      "Epoch 174/200\n",
      "50000/50000 [==============================] - 352s 7ms/step - loss: 0.0852 - acc: 0.9702 - val_loss: 0.5403 - val_acc: 0.8697\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 355s 7ms/step - loss: 0.0877 - acc: 0.9691 - val_loss: 0.5859 - val_acc: 0.8628\n",
      "Epoch 176/200\n",
      "50000/50000 [==============================] - 364s 7ms/step - loss: 0.0834 - acc: 0.9711 - val_loss: 0.5777 - val_acc: 0.8671\n",
      "Epoch 177/200\n",
      "50000/50000 [==============================] - 349s 7ms/step - loss: 0.0853 - acc: 0.9697 - val_loss: 0.5578 - val_acc: 0.8713\n",
      "Epoch 178/200\n",
      "50000/50000 [==============================] - 356s 7ms/step - loss: 0.0842 - acc: 0.9704 - val_loss: 0.5792 - val_acc: 0.8701\n",
      "Epoch 179/200\n",
      "50000/50000 [==============================] - 356s 7ms/step - loss: 0.0834 - acc: 0.9709 - val_loss: 0.5704 - val_acc: 0.8694\n",
      "Epoch 180/200\n",
      "50000/50000 [==============================] - 356s 7ms/step - loss: 0.0842 - acc: 0.9706 - val_loss: 0.5614 - val_acc: 0.8704\n",
      "Epoch 181/200\n",
      "50000/50000 [==============================] - 365s 7ms/step - loss: 0.0842 - acc: 0.9702 - val_loss: 0.5403 - val_acc: 0.8727\n",
      "Epoch 182/200\n",
      "50000/50000 [==============================] - 355s 7ms/step - loss: 0.0839 - acc: 0.9706 - val_loss: 0.5660 - val_acc: 0.8708\n",
      "Epoch 183/200\n",
      "50000/50000 [==============================] - 358s 7ms/step - loss: 0.0798 - acc: 0.9719 - val_loss: 0.5748 - val_acc: 0.8710\n",
      "Epoch 184/200\n",
      "50000/50000 [==============================] - 359s 7ms/step - loss: 0.0833 - acc: 0.9709 - val_loss: 0.5719 - val_acc: 0.8686\n",
      "Epoch 185/200\n",
      "50000/50000 [==============================] - 370s 7ms/step - loss: 0.0863 - acc: 0.9698 - val_loss: 0.5451 - val_acc: 0.8717\n",
      "Epoch 186/200\n",
      "50000/50000 [==============================] - 412s 8ms/step - loss: 0.0835 - acc: 0.9701 - val_loss: 0.5587 - val_acc: 0.8703\n",
      "Epoch 187/200\n",
      "50000/50000 [==============================] - 402s 8ms/step - loss: 0.0811 - acc: 0.9704 - val_loss: 0.5690 - val_acc: 0.8728\n",
      "Epoch 188/200\n",
      "50000/50000 [==============================] - 432s 9ms/step - loss: 0.0822 - acc: 0.9714 - val_loss: 0.5803 - val_acc: 0.8714\n",
      "Epoch 189/200\n",
      "50000/50000 [==============================] - 391s 8ms/step - loss: 0.0831 - acc: 0.9710 - val_loss: 0.5575 - val_acc: 0.8716\n",
      "Epoch 190/200\n",
      "50000/50000 [==============================] - 372s 7ms/step - loss: 0.0806 - acc: 0.9713 - val_loss: 0.5604 - val_acc: 0.8698\n",
      "Epoch 191/200\n",
      "50000/50000 [==============================] - 337s 7ms/step - loss: 0.0807 - acc: 0.9719 - val_loss: 0.5726 - val_acc: 0.8673\n",
      "Epoch 192/200\n",
      "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0806 - acc: 0.9717 - val_loss: 0.5644 - val_acc: 0.8706\n",
      "Epoch 193/200\n",
      "50000/50000 [==============================] - 332s 7ms/step - loss: 0.0795 - acc: 0.9721 - val_loss: 0.5781 - val_acc: 0.8739\n",
      "Epoch 194/200\n",
      "50000/50000 [==============================] - 333s 7ms/step - loss: 0.0820 - acc: 0.9713 - val_loss: 0.5647 - val_acc: 0.8702\n",
      "Epoch 195/200\n",
      "50000/50000 [==============================] - 333s 7ms/step - loss: 0.0790 - acc: 0.9717 - val_loss: 0.5648 - val_acc: 0.8705\n",
      "Epoch 196/200\n",
      "50000/50000 [==============================] - 358s 7ms/step - loss: 0.0786 - acc: 0.9721 - val_loss: 0.5699 - val_acc: 0.8689\n",
      "Epoch 197/200\n",
      "50000/50000 [==============================] - 396s 8ms/step - loss: 0.0807 - acc: 0.9715 - val_loss: 0.5874 - val_acc: 0.8705\n",
      "Epoch 198/200\n",
      "50000/50000 [==============================] - 391s 8ms/step - loss: 0.0792 - acc: 0.9718 - val_loss: 0.5580 - val_acc: 0.8734\n",
      "Epoch 199/200\n",
      "50000/50000 [==============================] - 348s 7ms/step - loss: 0.0773 - acc: 0.9720 - val_loss: 0.5488 - val_acc: 0.8743\n",
      "Epoch 200/200\n",
      "50000/50000 [==============================] - 338s 7ms/step - loss: 0.0838 - acc: 0.9703 - val_loss: 0.5472 - val_acc: 0.8745\n",
      "10000/10000 [==============================] - 13s 1ms/step\n",
      "[3 8 8 ... 5 1 7]\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train_data,labels_train,epochs=200,validation_data=(x_test_data,labels_test),batch_size=32)\n",
    "ypred=model.predict_classes(x_test_data,verbose=1)\n",
    "#score=model.evaluate(x_test_data,labels_test)\n",
    "\n",
    "print(ypred)\n",
    "\n",
    "b=np.array(ypred)\n",
    "df=pd.DataFrame(ypred)\n",
    "\n",
    "def f(s):\n",
    "    arr=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    return arr[s]\n",
    "    \n",
    "\n",
    "df.columns=['pred']\n",
    "df['result']=df.pred.apply(f)     \n",
    "del df['pred']\n",
    "#print(df)\n",
    "\n",
    "\n",
    "df.to_csv('re223_cifar10.csv',header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8745\n",
      "[3 8 8 ... 5 1 7]\n"
     ]
    }
   ],
   "source": [
    "print(sum(b==cls_test)/len(cls_test))\n",
    "print(cls_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
